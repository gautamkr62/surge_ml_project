{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a13e9f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 240214t.txt\n",
      "Processed 240215t.txt\n",
      "Processed 240216t.txt\n",
      "Processed 240217t.txt\n",
      "Processed 240218t.txt\n",
      "Processed 240219t.txt\n",
      "Processed 240220t.txt\n",
      "Processed 240221t.txt\n",
      "Processed 240222t.txt\n",
      "Processed 240223t.txt\n",
      "Processed 240224t.txt\n",
      "Processed 240225t.txt\n",
      "Processed 240226t.txt\n",
      "Processed 240227t.txt\n",
      "Processed 240228t.txt\n",
      "Processed 240229t.txt\n",
      "Processed 240301t.txt\n",
      "Processed 240302t.txt\n",
      "Processed 240303t.txt\n",
      "Processed 240304t.txt\n",
      "Processed 240305t.txt\n",
      "Processed 240306t.txt\n",
      "Processed 240307t.txt\n",
      "Processed 240308t.txt\n",
      "Processed 240309t.txt\n",
      "Processed 240310t.txt\n",
      "Processed 240311t.txt\n",
      "Processed 240312t.txt\n",
      "Processed 240313t.txt\n",
      "Processed 240314t.txt\n",
      "Processed 240315t.txt\n",
      "Processed 240316t.txt\n",
      "Processed 240317t.txt\n",
      "Processed 240318t.txt\n",
      "Processed 240319t.txt\n",
      "Processed 240320t.txt\n",
      "Processed 240321t.txt\n",
      "Processed 240322t.txt\n",
      "Processed 240323t.txt\n",
      "Processed 240324t.txt\n",
      "Processed 240325t.txt\n",
      "Processed 240326t.txt\n",
      "Processed 240327t.txt\n",
      "Processed 240328t.txt\n",
      "Processed 240329t.txt\n",
      "Processed 240330t.txt\n",
      "Processed 240331t.txt\n",
      "Processed 240401t.txt\n",
      "Processed 240402t.txt\n",
      "Processed 240403t.txt\n",
      "Processed 240404t.txt\n",
      "Processed 240405t.txt\n",
      "All data written to C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\PROJECT\\surge\\Bijoy_work\\Taiwan_2024\\one.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def parse_ionex_file(input_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    data_blocks = []\n",
    "    in_data_block = False\n",
    "    current_block = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "        if 'LAT/LON1/LON2' in line:\n",
    "            in_data_block = True\n",
    "            current_block = []\n",
    "            # Take the next 5 lines\n",
    "            for j in range(i + 1, i + 6):\n",
    "                if j < len(lines):\n",
    "                    current_block.extend(lines[j].strip().split())\n",
    "            data_blocks.extend(current_block)  # Extend data_blocks directly with current_block\n",
    "            # Move 5 lines ahead\n",
    "            i += 5\n",
    "        elif 'END OF TEC MAP' in line:\n",
    "            data_blocks.append(None)  # Insert a None to indicate the end of a TEC map block (optional)\n",
    "        i += 1\n",
    "\n",
    "    return data_blocks\n",
    "\n",
    "# Directory containing the IONEX files\n",
    "input_directory = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\PROJECT\\surge\\Bijoy_work\\Taiwan_2024'\n",
    "output_file_path = os.path.join(input_directory, 'one.csv')\n",
    "\n",
    "# Initialize a list to hold all columns\n",
    "all_columns = []\n",
    "\n",
    "# Date range\n",
    "start_date = datetime.strptime('240214', '%y%m%d')\n",
    "end_date = datetime.strptime('240405', '%y%m%d')\n",
    "\n",
    "# Loop through the date range\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    input_file_name = current_date.strftime('%y%m%dt.txt')\n",
    "    input_file_path = os.path.join(input_directory, input_file_name)\n",
    "    \n",
    "    if os.path.exists(input_file_path):\n",
    "        data_blocks = parse_ionex_file(input_file_path)\n",
    "        all_columns.append(data_blocks)\n",
    "        print(f'Processed {input_file_name}')\n",
    "    else:\n",
    "        print(f'{input_file_name} does not exist')\n",
    "    \n",
    "    current_date += timedelta(days=1)\n",
    "\n",
    "# Divide all elements by 10 and transpose the list of lists to align data into columns\n",
    "max_length = max(len(column) for column in all_columns)\n",
    "transposed_data = []\n",
    "\n",
    "for row_index in range(max_length):\n",
    "    row = []\n",
    "    for column in all_columns:\n",
    "        if row_index < len(column):\n",
    "            try:\n",
    "                value = float(column[row_index]) / 10  # Divide by 10\n",
    "            except ValueError:\n",
    "                value = column[row_index]  # In case of non-numeric values, keep the original value\n",
    "            row.append(value)\n",
    "        else:\n",
    "            row.append('')\n",
    "    transposed_data.append(row)\n",
    "\n",
    "# Write the transposed data to a single CSV file\n",
    "with open(output_file_path, 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerows(transposed_data)\n",
    "\n",
    "print(f'All data written to {output_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67966540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medians of every 3 consecutive elements in each row have been calculated and appended.\n",
      "New CSV file saved to: C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate the median of every 3 consecutive elements in a row\n",
    "def calculate_medians(row):\n",
    "    medians = []\n",
    "    for i in range(len(row) - 14):\n",
    "        window = row[i:i + 15]\n",
    "        ub = np.median(window) + 1.34 * np.std(window)  # Upper bound\n",
    "        medians.append(ub)\n",
    "    for i in range(len(row) - 14):\n",
    "        window = row[i:i + 15]\n",
    "        medians.append(np.median(window) - 1.34 * np.std(window))  # Lower bound\n",
    "        \n",
    "    return medians\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\one.csv'\n",
    "data = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# Calculate medians for each row and store them in a list of lists\n",
    "all_medians = []\n",
    "for idx, row in data.iterrows():\n",
    "    medians_of_row = calculate_medians(row)\n",
    "    all_medians.append(medians_of_row)\n",
    "\n",
    "# Convert the list of lists into a new DataFrame\n",
    "medians_df = pd.DataFrame(all_medians)\n",
    "\n",
    "# Concatenate the original DataFrame with the new medians DataFrame\n",
    "updated_data = pd.concat([data, medians_df], axis=1)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\output.csv'\n",
    "updated_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Medians of every 3 consecutive elements in each row have been calculated and appended.\")\n",
    "print(\"New CSV file saved to:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "136527ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\one.csv'\n",
    "data = pd.read_csv(file_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57e907c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.8</td>\n",
       "      <td>14.5</td>\n",
       "      <td>18.3</td>\n",
       "      <td>20.2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>17.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>16.7</td>\n",
       "      <td>...</td>\n",
       "      <td>19.8</td>\n",
       "      <td>25.6</td>\n",
       "      <td>28.2</td>\n",
       "      <td>28.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>25.7</td>\n",
       "      <td>18.3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.1</td>\n",
       "      <td>14.6</td>\n",
       "      <td>18.5</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.2</td>\n",
       "      <td>16.1</td>\n",
       "      <td>17.6</td>\n",
       "      <td>15.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>28.6</td>\n",
       "      <td>22.9</td>\n",
       "      <td>25.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.1</td>\n",
       "      <td>19.2</td>\n",
       "      <td>16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.4</td>\n",
       "      <td>14.6</td>\n",
       "      <td>18.7</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.5</td>\n",
       "      <td>16.2</td>\n",
       "      <td>17.8</td>\n",
       "      <td>15.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>16.9</td>\n",
       "      <td>...</td>\n",
       "      <td>20.2</td>\n",
       "      <td>25.9</td>\n",
       "      <td>28.5</td>\n",
       "      <td>28.8</td>\n",
       "      <td>23.2</td>\n",
       "      <td>26.1</td>\n",
       "      <td>18.5</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.3</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>18.9</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>16.4</td>\n",
       "      <td>17.9</td>\n",
       "      <td>15.4</td>\n",
       "      <td>18.3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.6</td>\n",
       "      <td>28.9</td>\n",
       "      <td>23.4</td>\n",
       "      <td>26.3</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.4</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.9</td>\n",
       "      <td>14.7</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.8</td>\n",
       "      <td>16.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>18.5</td>\n",
       "      <td>17.1</td>\n",
       "      <td>...</td>\n",
       "      <td>20.5</td>\n",
       "      <td>26.1</td>\n",
       "      <td>28.7</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.4</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124387</th>\n",
       "      <td>27.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>20.5</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.2</td>\n",
       "      <td>17.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>23.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>...</td>\n",
       "      <td>18.2</td>\n",
       "      <td>21.6</td>\n",
       "      <td>15.5</td>\n",
       "      <td>11.9</td>\n",
       "      <td>17.6</td>\n",
       "      <td>14.6</td>\n",
       "      <td>14.1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>18.1</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124388</th>\n",
       "      <td>27.3</td>\n",
       "      <td>18.1</td>\n",
       "      <td>25.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.2</td>\n",
       "      <td>17.6</td>\n",
       "      <td>22.6</td>\n",
       "      <td>23.8</td>\n",
       "      <td>21.7</td>\n",
       "      <td>...</td>\n",
       "      <td>18.3</td>\n",
       "      <td>21.7</td>\n",
       "      <td>15.6</td>\n",
       "      <td>11.9</td>\n",
       "      <td>17.6</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>18.1</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124389</th>\n",
       "      <td>27.4</td>\n",
       "      <td>18.2</td>\n",
       "      <td>25.9</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.1</td>\n",
       "      <td>17.8</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>...</td>\n",
       "      <td>18.4</td>\n",
       "      <td>21.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>11.9</td>\n",
       "      <td>17.6</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124390</th>\n",
       "      <td>27.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>25.9</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.1</td>\n",
       "      <td>17.8</td>\n",
       "      <td>22.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>21.8</td>\n",
       "      <td>...</td>\n",
       "      <td>18.5</td>\n",
       "      <td>21.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>11.9</td>\n",
       "      <td>17.6</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.1</td>\n",
       "      <td>14.1</td>\n",
       "      <td>18.1</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124391</th>\n",
       "      <td>27.7</td>\n",
       "      <td>18.3</td>\n",
       "      <td>26.1</td>\n",
       "      <td>20.2</td>\n",
       "      <td>20.2</td>\n",
       "      <td>20.1</td>\n",
       "      <td>17.9</td>\n",
       "      <td>22.9</td>\n",
       "      <td>24.2</td>\n",
       "      <td>21.8</td>\n",
       "      <td>...</td>\n",
       "      <td>18.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>11.9</td>\n",
       "      <td>17.7</td>\n",
       "      <td>14.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124392 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2     3     4     5     6     7     8     9   ...    42  \\\n",
       "0       19.8  14.5  18.3  20.2  20.0  15.9  17.4  15.0  17.8  16.7  ...  19.8   \n",
       "1       20.1  14.6  18.5  20.3  20.2  16.1  17.6  15.2  18.0  16.8  ...  20.0   \n",
       "2       20.4  14.6  18.7  20.3  20.5  16.2  17.8  15.2  18.2  16.9  ...  20.2   \n",
       "3       20.7  14.7  18.9  20.3  20.6  16.4  17.9  15.4  18.3  17.0  ...  20.3   \n",
       "4       20.9  14.7  19.0  20.3  20.8  16.5  18.0  15.4  18.5  17.1  ...  20.5   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "124387  27.2  18.0  25.6  20.5  19.8  20.2  17.5  22.5  23.6  21.6  ...  18.2   \n",
       "124388  27.3  18.1  25.7  20.4  19.9  20.2  17.6  22.6  23.8  21.7  ...  18.3   \n",
       "124389  27.4  18.2  25.9  20.4  19.9  20.1  17.8  22.7  23.9  21.8  ...  18.4   \n",
       "124390  27.6  18.2  25.9  20.3  20.1  20.1  17.8  22.8  24.1  21.8  ...  18.5   \n",
       "124391  27.7  18.3  26.1  20.2  20.2  20.1  17.9  22.9  24.2  21.8  ...  18.5   \n",
       "\n",
       "          43    44    45    46    47    48    49    50    51  \n",
       "0       25.6  28.2  28.5  22.7  25.7  18.3  19.0  19.2  16.6  \n",
       "1       25.8  28.4  28.6  22.9  25.9  18.4  19.1  19.2  16.7  \n",
       "2       25.9  28.5  28.8  23.2  26.1  18.5  19.3  19.3  16.9  \n",
       "3       26.0  28.6  28.9  23.4  26.3  18.6  19.3  19.4  17.0  \n",
       "4       26.1  28.7  29.0  23.5  26.5  18.7  19.4  19.4  17.1  \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "124387  21.6  15.5  11.9  17.6  14.6  14.1  13.9  18.1  11.7  \n",
       "124388  21.7  15.6  11.9  17.6  14.7  14.1  13.9  18.1  11.7  \n",
       "124389  21.8  15.8  11.9  17.6  14.7  14.1  14.0  18.1  11.7  \n",
       "124390  21.9  15.9  11.9  17.6  14.7  14.1  14.1  18.1  11.7  \n",
       "124391  22.0  15.9  11.9  17.7  14.8  14.0  14.2  18.0  11.6  \n",
       "\n",
       "[124392 rows x 52 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1875a3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate the median of every 15 consecutive elements in a row\n",
    "def calculate_medians(row):\n",
    "    upper_bounds = []\n",
    "    lower_bounds = []\n",
    "    # Just to make sure that we don't consider the last window.\n",
    "    # so put len(row) - 15\n",
    "    for i in range(len(row) - 15):\n",
    "        window = row[i:i + 15]\n",
    "        median = np.median(window)\n",
    "        std_dev = np.std(window)\n",
    "        upper_bound = median + 1.34 * std_dev  # Upper bound\n",
    "        lower_bound = median - 1.34 * std_dev  # Lower bound\n",
    "        upper_bounds.append(upper_bound)\n",
    "        lower_bounds.append(lower_bound)\n",
    "    return upper_bounds, lower_bounds\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\one.csv'\n",
    "data = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# Calculate medians for each row and store them in a list of lists\n",
    "all_upper_bounds = []\n",
    "all_lower_bounds = []\n",
    "for idx, row in data.iterrows():\n",
    "    upper_bounds, lower_bounds = calculate_medians(row)\n",
    "    all_upper_bounds.append(upper_bounds)\n",
    "    all_lower_bounds.append(lower_bounds)\n",
    "\n",
    "# Convert the list of lists into new DataFrames\n",
    "upper_bounds_df = pd.DataFrame(all_upper_bounds)\n",
    "lower_bounds_df = pd.DataFrame(all_lower_bounds)\n",
    "\n",
    "# Concatenate the original DataFrame with the new medians DataFrame\n",
    "updated_data = pd.concat([data, upper_bounds_df, lower_bounds_df], axis=1)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\Final_output.csv'\n",
    "updated_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Upper and lower bounds for medians of every 15 consecutive elements in each row have been calculated and appended.\")\n",
    "print(\"New CSV file saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f229ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5074d21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Latitude: 86\n",
      "Enter the Longitude: 101\n",
      "85.0 100\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b356187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Take input for two floating-point numbers in Jupyter Notebook\n",
    "lat_start = float(input(\"Enter the starting latitude (e.g., 87.5): \"))\n",
    "lat_end = float(input(\"Enter the ending latitude (e.g., -87.5): \"))\n",
    "\n",
    "# Define the number of points\n",
    "num_lat_points = 71\n",
    "num_lon_points = 73\n",
    "\n",
    "# Calculate the step size for latitude and longitude\n",
    "latitudes = np.linspace(lat_start, lat_end, num_lat_points)\n",
    "longitudes = np.linspace(-180, 180, num_lon_points)\n",
    "\n",
    "# Generate all combinations of latitude and longitude\n",
    "lat_lon_combinations = [(lat, lon) for lat in latitudes for lon in longitudes]\n",
    "\n",
    "# Create a DataFrame from the combinations\n",
    "df = pd.DataFrame(lat_lon_combinations, columns=['Latitude', 'Longitude'])\n",
    "\n",
    "# Repeat the DataFrame 24 times\n",
    "df_repeated = pd.concat([df] * 24, ignore_index=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\lat_lon_repeated.csv'\n",
    "df_repeated.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Latitude and Longitude combinations have been repeated 24 times and saved to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f59f636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Imported and their upper and lower bound created..\n",
    "# Remove the first 15 columns from TEc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "608db5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program to generate all Latitude and longitude\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of points\n",
    "num_lat_points = 71\n",
    "num_lon_points = 73\n",
    "\n",
    "# Calculate the step size for latitude and longitude\n",
    "latitudes = np.linspace(87.5, -87.5, num_lat_points)\n",
    "longitudes = np.linspace(-180, 180, num_lon_points)\n",
    "\n",
    "# Generate all combinations of latitude and longitude\n",
    "lat_lon_combinations = [(lat, lon) for lat in latitudes for lon in longitudes]\n",
    "\n",
    "# Create a DataFrame from the combinations\n",
    "df = pd.DataFrame(lat_lon_combinations, columns=['Latitude', 'Longitude'])\n",
    "\n",
    "# Repeat the DataFrame 24 times\n",
    "df_repeated = pd.concat([df] * 24, ignore_index=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# output_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\lat_lon_repeated.csv'\n",
    "# df_repeated.to_csv(output_path, index=False)\n",
    "\n",
    "# print(\"Latitude and Longitude combinations have been repeated 24 times and saved to CSV.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4de53a4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Porgram to get desired Latitude and Longitude..\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Generating Nearest Latitude and Longitude.\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m Lat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter the Latitude: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      5\u001b[0m Lon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the Longitude: \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Find nearest multiple of 2.5 from latitude\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py:1191\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py:1234\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1232\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Porgram to get desired Latitude and Longitude..\n",
    "# Generating Nearest Latitude and Longitude.\n",
    "\n",
    "Lat = float(input(\"Enter the Latitude: \"))\n",
    "Lon = float(input(\"Enter the Longitude: \"))\n",
    "\n",
    "# Find nearest multiple of 2.5 from latitude\n",
    "\n",
    "Lat = round(Lat / 2.5) * 2.5\n",
    "Lon = round(Lon / 5) * 5\n",
    "print(Lat, Lon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f600dbbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\gauta\\\\OneDrive - IIT Kanpur\\\\Desktop\\\\PROJECT\\\\surge\\\\Bijoy_work\\\\Taiwan_2024\\\\csv files\\\\1_initial_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load the CSV file\u001b[39;00m\n\u001b[0;32m      6\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgauta\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive - IIT Kanpur\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPROJECT\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msurge\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBijoy_work\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTaiwan_2024\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcsv files\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1_initial_dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 7\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m data\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# # Take input for the desired latitude and longitude\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Lat = float(input(\"Enter the desired latitude: \"))\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Lon = float(input(\"Enter the desired longitude: \"))\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#     print(f\"Number of matching rows: {len(filtered_data)}\")\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#     print(\"New CSV file saved to:\", output_path)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\gauta\\\\OneDrive - IIT Kanpur\\\\Desktop\\\\PROJECT\\\\surge\\\\Bijoy_work\\\\Taiwan_2024\\\\csv files\\\\1_initial_dataset.csv'"
     ]
    }
   ],
   "source": [
    "# To search for desired lat and long and separate it as a file.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\PROJECT\\surge\\Bijoy_work\\Taiwan_2024\\csv files\\1_initial_dataset.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data\n",
    "\n",
    "# Take input for the desired latitude and longitude\n",
    "Lat = float(input(\"Enter the desired latitude: \"))\n",
    "Lon = float(input(\"Enter the desired longitude: \"))\n",
    "Lat = round(Lat / 2.5) * 2.5\n",
    "Lon = round(Lon / 5) * 5\n",
    "\n",
    "\n",
    "# Filter the rows that match the desired latitude and longitude\n",
    "filtered_data = data[(data['Latitude'] == Lat) & (data['Longitude'] == Lon)]\n",
    "\n",
    "# Check if there are any matching rows\n",
    "if filtered_data.empty:\n",
    "    print(\"No matching rows found.\")\n",
    "else:\n",
    "    # Save the filtered rows to a new CSV file\n",
    "    output_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\PROJECT\\surge\\Bijoy_work\\Taiwan_2024\\csv files\\SEPARATED_WITH_LAT_AND_LONG.csv'\n",
    "    filtered_data.to_csv(output_path, index=False)\n",
    "    print(\"Filtered rows have been saved to CSV.\")\n",
    "    print(f\"Number of matching rows: {len(filtered_data)}\")\n",
    "    print(\"New CSV file saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8f5857d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program for dates repeating\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\PROJECT\\surge\\Bijoy_work\\Taiwan_2024\\csv files\\6_filtered_lat_lon.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove the first two columns (latitude and longitude)\n",
    "df = df.iloc[:, 2:]\n",
    "\n",
    "# Extract only the first 37 dates from the header (first row) after removing latitude and longitude\n",
    "dates = list(df.columns[:37])\n",
    "\n",
    "# Initialize an empty list to store repeated dates\n",
    "repeated_dates = []\n",
    "\n",
    "# Repeat each date 24 times sequentially\n",
    "for date in dates:\n",
    "    repeated_dates.extend([date] * 24)\n",
    "\n",
    "# Initialize a new DataFrame for flattened data including dates\n",
    "flattened_df = pd.DataFrame({'Date': repeated_dates})\n",
    "\n",
    "# Flatten each set of 37 columns into new columns\n",
    "num_cols = df.shape[1]\n",
    "num_sets = num_cols // 37\n",
    "\n",
    "for i in range(num_sets):\n",
    "    start_col = i * 37\n",
    "    end_col = (i + 1) * 37\n",
    "    subset = df.iloc[:, start_col:end_col].stack().reset_index(drop=True)\n",
    "    if i == 0:\n",
    "        flattened_df['TEC'] = subset\n",
    "    elif i == 1:\n",
    "        flattened_df['UB'] = subset\n",
    "    elif i == 2:\n",
    "        flattened_df['LB'] = subset\n",
    "\n",
    "# Save the flattened DataFrame to a new CSV file\n",
    "output_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\PROJECT\\surge\\Bijoy_work\\Taiwan_2024\\csv files\\output_with_repeated_dates.csv'\n",
    "flattened_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"DataFrame has been flattened into three columns with each date repeated 24 times sequentially in the 'Date' column.\")\n",
    "print(\"CSV file saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2162b145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been flattened into three columns (TEC, UB, LB) with each date in the 'Date' column, followed by 23 NaNs.\n",
      "CSV file saved to: C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\PROJECT\\surge\\Bijoy_work\\Taiwan_2024\\csv files\\WRONG_OUTPUT.csv\n"
     ]
    }
   ],
   "source": [
    "# program for dates not repeating leaving 23 blankspaces.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\PROJECT\\surge\\Bijoy_work\\Taiwan_2024\\csv files\\6_filtered_lat_lon.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove the first two columns (latitude and longitude)\n",
    "df = df.iloc[:, 2:]\n",
    "\n",
    "# Extract only the first 37 dates from the header (first row) after removing latitude and longitude\n",
    "dates = list(df.columns[:37])\n",
    "\n",
    "# Initialize lists to hold the 'Date' column and NaN values\n",
    "Date = []\n",
    "NaNs = [np.nan] * 24  # List of 24 NaN values\n",
    "\n",
    "# Construct the 'Date' column with NaNs in between\n",
    "for i in range(24 * 37):\n",
    "    if i % 24 == 0:\n",
    "        Date.append(dates[i // 24])  # Append the date every 24 rows\n",
    "    else:\n",
    "        Date.append(np.nan)  # Append NaN for other rows\n",
    "\n",
    "# Create a new DataFrame with 'Date', 'TEC', 'UB', 'LB' columns\n",
    "flattened_df = pd.DataFrame({\n",
    "    'Date': Date,\n",
    "    'TEC': np.nan,\n",
    "    'UB': np.nan,\n",
    "    'LB': np.nan\n",
    "})\n",
    "\n",
    "# Flatten each set of 37 columns into new columns\n",
    "num_cols = df.shape[1]\n",
    "num_sets = num_cols // 37\n",
    "\n",
    "for i in range(num_sets):\n",
    "    start_col = i * 37\n",
    "    end_col = (i + 1) * 37\n",
    "    subset = df.iloc[:, start_col:end_col].values.flatten()\n",
    "    column_name = f'Column_{i + 1}'\n",
    "    if i == 0:\n",
    "        flattened_df['TEC'] = subset\n",
    "    elif i == 1:\n",
    "        flattened_df['UB'] = subset\n",
    "    elif i == 2:\n",
    "        flattened_df['LB'] = subset\n",
    "\n",
    "# Save the flattened DataFrame to a new CSV file\n",
    "output_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\PROJECT\\surge\\Bijoy_work\\Taiwan_2024\\csv files\\WRONG_OUTPUT.csv'\n",
    "flattened_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"DataFrame has been flattened into three columns (TEC, UB, LB) with each date in the 'Date' column, followed by 23 NaNs.\")\n",
    "print(\"CSV file saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae5ac611",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m dates \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(df\u001b[38;5;241m.\u001b[39mcolumns[:\u001b[38;5;241m37\u001b[39m], df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Create a new DataFrame with the flattened columns\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m flattened_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdates\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTEC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mTEC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mUB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mLB\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Save the flattened DataFrame to a new CSV file\u001b[39;00m\n\u001b[0;32m     35\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgauta\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive - IIT Kanpur\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPROJECT\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msurge\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBijoy_work\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTaiwan_2024\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcsv files\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUPDATED_OUTPUT.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:736\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    730\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    731\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    732\u001b[0m     )\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\PROJECT\\surge\\Bijoy_work\\Taiwan_2024\\csv files\\7_52_days_filtered_lat_lon_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove the first two columns (latitude and longitude)\n",
    "df = df.iloc[:, 2:]\n",
    "\n",
    "# Number of columns in the original DataFrame after removing latitude and longitude columns\n",
    "num_cols = df.shape[1]\n",
    "\n",
    "# Ensure that we have exactly 111 columns (37 for each of TEC, UB, and LB)\n",
    "if num_cols != 111:\n",
    "    raise ValueError(f\"Expected 111 columns (37 each for TEC, UB, and LB), but found {num_cols} columns.\")\n",
    "\n",
    "# Flatten each set of 37 columns into separate lists\n",
    "TEC = df.iloc[:, :37].values.flatten()\n",
    "UB = df.iloc[:, 37:74].values.flatten()\n",
    "LB = df.iloc[:, 74:111].values.flatten()\n",
    "\n",
    "# Repeat the first 37 dates to match the length of the flattened columns\n",
    "dates = np.tile(df.columns[:37], df.shape[0])\n",
    "\n",
    "# Create a new DataFrame with the flattened columns\n",
    "flattened_df = pd.DataFrame({\n",
    "    'Date': np.concatenate([dates, dates, dates]),\n",
    "    'TEC': TEC,\n",
    "    'UB': UB,\n",
    "    'LB': LB\n",
    "})\n",
    "\n",
    "# Save the flattened DataFrame to a new CSV file\n",
    "output_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\PROJECT\\surge\\Bijoy_work\\Taiwan_2024\\csv files\\UPDATED_OUTPUT.csv'\n",
    "flattened_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"DataFrame has been flattened into three columns (TEC, UB, LB) with each date in the 'Date' column.\")\n",
    "print(\"CSV file saved to:\", output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
