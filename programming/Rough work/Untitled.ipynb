{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87461eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def parse_ionex_file(input_file, output_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    data_blocks = []\n",
    "    in_data_block = False\n",
    "    current_block = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "        if 'LAT/LON1/LON2' in line:\n",
    "            in_data_block = True\n",
    "            current_block = []\n",
    "            # Take the next 5 lines\n",
    "            for j in range(i + 1, i + 6):\n",
    "                if j < len(lines):\n",
    "                    current_block.extend(lines[j].strip().split())\n",
    "            data_blocks.append(current_block)\n",
    "            # Move 5 lines ahead\n",
    "            i += 5\n",
    "        elif 'END OF TEC MAP' in line:\n",
    "            data_blocks.append([])\n",
    "        i += 1\n",
    "\n",
    "    # Write the data blocks to a new CSV file\n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        for block in data_blocks:\n",
    "            csvwriter.writerow(block)\n",
    "\n",
    "# Replace with your actual input file path and desired output file path\n",
    "input_file_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\PROJECT\\surge\\Bijoy_work\\IONEX_FILES\\GPSG0750.21I'\n",
    "output_file_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\PROJECT\\surge\\Bijoy_work\\IONEX_FILES\\New_check.csv'\n",
    "\n",
    "parse_ionex_file(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adae5a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def parse_ionex_file(input_file, output_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    data_blocks = []\n",
    "    in_data_block = False\n",
    "    current_block = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "        if 'LAT/LON1/LON2' in line:\n",
    "            in_data_block = True\n",
    "            current_block = []\n",
    "            # Take the next 5 lines\n",
    "            for j in range(i + 1, i + 6):\n",
    "                if j < len(lines):\n",
    "                    current_block.extend(lines[j].strip().split())\n",
    "            data_blocks.extend(current_block)  # Extend data_blocks directly with current_block\n",
    "            # Move 5 lines ahead\n",
    "            i += 5\n",
    "        elif 'END OF TEC MAP' in line:\n",
    "            data_blocks.append(None)  # Insert a None to indicate the end of a TEC map block (optional)\n",
    "        i += 1\n",
    "\n",
    "    # Write the data blocks to a new CSV file\n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        for item in data_blocks:\n",
    "            if item is not None:\n",
    "                csvwriter.writerow([item])  # Write each item as a single column\n",
    "\n",
    "# Replace with your actual input file path and desired output file path\n",
    "input_file_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\PROJECT\\surge\\Bijoy_work\\IONEX_FILES\\GPSG0750.21I'\n",
    "output_file_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\PROJECT\\surge\\Bijoy_work\\IONEX_FILES\\first.csv'\n",
    "\n",
    "parse_ionex_file(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6faca85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GPSG0750.21I\n",
      "Processed GPSG0760.21I\n",
      "Processed GPSG0770.21I\n",
      "Processed GPSG0780.21I\n",
      "Processed GPSG0790.21I\n",
      "Processed GPSG0800.21I\n",
      "Processed GPSG0810.21I\n",
      "Processed GPSG0820.21I\n",
      "Processed GPSG0830.21I\n",
      "Processed GPSG0840.21I\n",
      "All data written to C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\PROJECT\\surge\\Bijoy_work\\IONEX_FILES\\all_data.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def parse_ionex_file(input_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    data_blocks = []\n",
    "    in_data_block = False\n",
    "    current_block = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "        if 'LAT/LON1/LON2' in line:\n",
    "            in_data_block = True\n",
    "            current_block = []\n",
    "            # Take the next 5 lines\n",
    "            for j in range(i + 1, i + 6):\n",
    "                if j < len(lines):\n",
    "                    current_block.extend(lines[j].strip().split())\n",
    "            data_blocks.extend(current_block)  # Extend data_blocks directly with current_block\n",
    "            # Move 5 lines ahead\n",
    "            i += 5\n",
    "        elif 'END OF TEC MAP' in line:\n",
    "            data_blocks.append(None)  # Insert a None to indicate the end of a TEC map block (optional)\n",
    "        i += 1\n",
    "\n",
    "    return data_blocks\n",
    "\n",
    "# Directory containing the IONEX files\n",
    "input_directory = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\PROJECT\\surge\\Bijoy_work\\IONEX_FILES'\n",
    "output_file_path = os.path.join(input_directory, 'all_data.csv')\n",
    "\n",
    "# Initialize a list to hold all columns\n",
    "all_columns = []\n",
    "\n",
    "# Loop through the specified range of files\n",
    "for i in range(750, 841, 10):\n",
    "    input_file_name = f'GPSG0{i:02d}.21I'\n",
    "    input_file_path = os.path.join(input_directory, input_file_name)\n",
    "    \n",
    "    if os.path.exists(input_file_path):\n",
    "        data_blocks = parse_ionex_file(input_file_path)\n",
    "        all_columns.append(data_blocks)\n",
    "        print(f'Processed {input_file_name}')\n",
    "    else:\n",
    "        print(f'{input_file_name} does not exist')\n",
    "\n",
    "# Transpose the list of lists to align data into columns\n",
    "max_length = max(len(column) for column in all_columns)\n",
    "transposed_data = []\n",
    "\n",
    "for row_index in range(max_length):\n",
    "    row = []\n",
    "    for column in all_columns:\n",
    "        if row_index < len(column):\n",
    "            row.append(column[row_index])\n",
    "        else:\n",
    "            row.append('')\n",
    "    transposed_data.append(row)\n",
    "\n",
    "# Write the transposed data to a single CSV file\n",
    "with open(output_file_path, 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerows(transposed_data)\n",
    "\n",
    "print(f'All data written to {output_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f690f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\PROJECT\\surge\\Bijoy_work\\IONEX_FILES\\GPSG0750.csv' read successfully.\n",
      "Printing first few rows to verify:\n",
      "   111  107  102  95  92  92.1  92.2  92.3  92.4  92.5  ...  94  100  105  \\\n",
      "0  111  107  102  95  92    92    92    92    92    92  ...  94  100  105   \n",
      "1  111  107  102  95  92    92    92    92    92    92  ...  94  100  105   \n",
      "2  111  107  102  95  92    92    92    92    92    92  ...  94  100  105   \n",
      "3  111  107  102  95  92    92    92    92    92    92  ...  94  100  105   \n",
      "4  111  107  102  95  92    92    92    92    92    92  ...  94  100  105   \n",
      "\n",
      "   110  113  116  117  116.1  115  111.1  \n",
      "0  110  113  116  117    116  115    111  \n",
      "1  110  113  116  117    116  115    111  \n",
      "2  110  113  116  117    116  115    111  \n",
      "3  110  113  116  117    116  115    111  \n",
      "4  110  113  116  117    116  115    111  \n",
      "\n",
      "[5 rows x 73 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to check if a file is read successfully\n",
    "def check_file_read(file_path):\n",
    "    try:\n",
    "        # Attempt to read the CSV file\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"File '{file_path}' read successfully.\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{file_path}' not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file '{file_path}': {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "file_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\PROJECT\\surge\\Bijoy_work\\IONEX_FILES\\GPSG0750.csv'\n",
    "data = check_file_read(file_path)\n",
    "\n",
    "# Perform further actions if file was read successfully\n",
    "if data is not None:\n",
    "    print(\"Printing first few rows to verify:\")\n",
    "    print(data.head())\n",
    "    # Additional processing or validation can be done here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d008f039",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m     row \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mtolist()  \u001b[38;5;66;03m# Convert row to list to modify it\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     row\u001b[38;5;241m.\u001b[39mextend([np\u001b[38;5;241m.\u001b[39mnan] \u001b[38;5;241m+\u001b[39m means_of_row)  \u001b[38;5;66;03m# Append NaN followed by means to the row\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m row  \u001b[38;5;66;03m# Update the row in the DataFrame\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Save the updated DataFrame to a new CSV file\u001b[39;00m\n\u001b[0;32m     24\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgauta\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive - IIT Kanpur\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPROJECT\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msurge\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBijoy_work\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mIONEX_FILES\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGPSG0750_with_means.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:885\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    884\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 885\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1893\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[0;32m   1892\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[1;32m-> 1893\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1894\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1978\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_column(ilocs[\u001b[38;5;241m0\u001b[39m], value, pi)\n\u001b[0;32m   1977\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1978\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1979\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust have equal len keys and value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1980\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen setting with an iterable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1981\u001b[0m         )\n\u001b[0;32m   1983\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1984\u001b[0m     \u001b[38;5;66;03m# scalar value\u001b[39;00m\n\u001b[0;32m   1985\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m loc \u001b[38;5;129;01min\u001b[39;00m ilocs:\n",
      "\u001b[1;31mValueError\u001b[0m: Must have equal len keys and value when setting with an iterable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate the mean of every 3 consecutive elements in a row\n",
    "def calculate_means(row):\n",
    "    means = []\n",
    "    for i in range(len(row) - 2):\n",
    "        window = row[i:i+3]\n",
    "        means.append(np.mean(window))\n",
    "    return means\n",
    "\n",
    "# Load the CSV fileg\n",
    "file_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\PROJECT\\surge\\Bijoy_work\\IONEX_FILES\\GPSG0760.csv'  # Replace with the actual file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate means for each row and append means to each respective row\n",
    "for idx, row in data.iterrows():\n",
    "    means_of_row = calculate_means(row)\n",
    "    row = row.tolist()  # Convert row to list to modify it\n",
    "    row.extend([np.nan] + means_of_row)  # Append NaN followed by means to the row\n",
    "    data.iloc[idx] = row  # Update the row in the DataFrame\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_path = r'C:\\Users\\gauta\\OneDrive - IIT Kanpur\\Desktop\\PROJECT\\surge\\Bijoy_work\\IONEX_FILES\\GPSG0750_with_means.csv'\n",
    "data.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Means of all continuous three elements in each row have been appended.\")\n",
    "print(\"Updated CSV file saved to:\", output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
